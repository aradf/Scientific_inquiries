{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2942eabc",
   "metadata": {},
   "source": [
    "# üéì YOLO v5 Objects Detection: Label, Train and Test\n",
    "\n",
    "### &nbsp; &nbsp; üéõÔ∏è Section 3: Create custom dataset in YOLO format\n",
    "#### &nbsp; &nbsp; &nbsp; üî£ Lecture: Create custom dataset\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**Description:**  \n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*`Apply` toolkit to extract images with needed classes of objects. `Specify` parameters to get images of needed quality.*  \n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**File:** *`create_custom_dataset.ipynb`*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10657b59",
   "metadata": {},
   "source": [
    "### üí° Algorithm:<a name=\"algorithm\"></a>\n",
    "\n",
    "**‚úîÔ∏è Step 1:** [Set up prerequisites](#step1)  \n",
    "**‚úîÔ∏è Step 2:** [Download custom dataset](#step2)  \n",
    "**‚úîÔ∏è Step 3:** [Load dataset from hard drive](#step3)  \n",
    "  \n",
    "  \n",
    "### üéØ **Results:**  \n",
    "**‚úÖ Custom dataset** with images and annotations  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d901ea62",
   "metadata": {},
   "source": [
    "<a name=\"step1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eccc72",
   "metadata": {},
   "source": [
    " ‚áß [Back to Algorithm](#algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d89c6b",
   "metadata": {},
   "source": [
    "# üì• Step 1: Set up prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da85c5",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìú **Content:**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí† 1.**1** **Load** needed libraries  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí† 1.**2** **Change** active directory  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí† 1.**3** **Set up** path where to save dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f621b",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff6481",
   "metadata": {},
   "source": [
    "### üí† 1.1 Load needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e5c0b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries are successfully loaded üëå\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo          # To use all the FiftyOne functionality\n",
    "import fiftyone.zoo as foz     # To download custom dataset from Open Images Dataset\n",
    "import os                      # To use operating system dependent functionality\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Hint: to print emoji via Unicode, replace '+' with '000' and add prefix '\\'\n",
    "# For instance, emoji with Unicode 'U+1F44C' can be printed as '\\U0001F44C'\n",
    "print(\"Libraries are successfully loaded \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7de298",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5efd421",
   "metadata": {},
   "source": [
    "### üí† 1.2 Change active directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d674e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently active directory is:\n",
      "/home/montecarlo/Desktop/scientific_computing/yolov5_course/section3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check point\n",
    "# Showing currently active directory\n",
    "print('Currently active directory is:')\n",
    "print(os.getcwd())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514726c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently active directory is:\n",
      "/home/montecarlo/Desktop/scientific_computing/yolov5_course/section3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check point\n",
    "# Showing currently active directory\n",
    "print('Currently active directory is:')\n",
    "print(os.getcwd())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43f9066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory to be activated is:\n",
      "/home/montecarlo/Desktop/scientific_computing/yolov5_course/section3/custom_dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparing directory to be activated\n",
    "directory_to_save_dataset = os.path.join(os.getcwd(), \"custom_dataset\")\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('The directory to be activated is:')\n",
    "print(directory_to_save_dataset)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ebc5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The needed directory is successfully activated üëå\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Activating needed directory\n",
    "os.chdir(directory_to_save_dataset)\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The needed directory is successfully activated \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d57bfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently active directory is:\n",
      "/home/montecarlo/Desktop/scientific_computing/yolov5_course/section3/custom_dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check point\n",
    "# Showing currently active directory\n",
    "print('Currently active directory is:')\n",
    "print(os.getcwd())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9735026",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d7410",
   "metadata": {},
   "source": [
    "### üí† 1.3 Set up path where to save dataset\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Configuration options:**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/user_guide/config.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e127d187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"allow_legacy_orchestrators\": false,\n",
      "    \"batcher_static_size\": 100,\n",
      "    \"batcher_target_latency\": 0.2,\n",
      "    \"batcher_target_size_bytes\": 1048576,\n",
      "    \"database_admin\": true,\n",
      "    \"database_dir\": \"/home/montecarlo/.fiftyone/var/lib/mongo\",\n",
      "    \"database_name\": \"fiftyone\",\n",
      "    \"database_uri\": null,\n",
      "    \"database_validation\": true,\n",
      "    \"dataset_zoo_dir\": \"/home/montecarlo/fiftyone\",\n",
      "    \"dataset_zoo_manifest_paths\": null,\n",
      "    \"default_app_address\": \"localhost\",\n",
      "    \"default_app_port\": 5151,\n",
      "    \"default_batch_size\": null,\n",
      "    \"default_batcher\": \"latency\",\n",
      "    \"default_dataset_dir\": \"/home/montecarlo/fiftyone\",\n",
      "    \"default_image_ext\": \".jpg\",\n",
      "    \"default_ml_backend\": null,\n",
      "    \"default_sequence_idx\": \"%06d\",\n",
      "    \"default_video_ext\": \".mp4\",\n",
      "    \"do_not_track\": false,\n",
      "    \"logging_level\": \"INFO\",\n",
      "    \"max_process_pool_workers\": null,\n",
      "    \"max_thread_pool_workers\": null,\n",
      "    \"model_zoo_dir\": \"/home/montecarlo/fiftyone/__models__\",\n",
      "    \"model_zoo_manifest_paths\": null,\n",
      "    \"module_path\": null,\n",
      "    \"operator_timeout\": 600,\n",
      "    \"plugins_cache_enabled\": false,\n",
      "    \"plugins_dir\": \"/home/montecarlo/fiftyone/__plugins__\",\n",
      "    \"requirement_error_level\": 0,\n",
      "    \"show_progress_bars\": true,\n",
      "    \"timezone\": null\n",
      "}\n",
      "\n",
      "/home/montecarlo/fiftyone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check point\n",
    "# Showing current configuration\n",
    "print(fo.config)\n",
    "print()\n",
    "print(fo.config.dataset_zoo_dir)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9caa371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/montecarlo/Desktop/scientific_computing/yolov5_course/section3/custom_dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assigning new path where to save downloaded dataset\n",
    "fo.config.dataset_zoo_dir = directory_to_save_dataset\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing current configuration\n",
    "print(fo.config.dataset_zoo_dir)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d07fe",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3154bc2c",
   "metadata": {},
   "source": [
    "<a name=\"step2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3ca12",
   "metadata": {},
   "source": [
    " ‚áß [Back to Algorithm](#algorithm) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ‚áß [Back to Step 1 content](#step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3001ec9",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Step 2: Download custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d390d",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìú **Content:**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí† 2.**1** **Download** small validation dataset  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí† 2.**2** **Download** full validation dataset  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí† 2.**3** **Download** full test dataset  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí† 2.**4** **Download** full train dataset  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef14ad12",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a47a1",
   "metadata": {},
   "source": [
    "### üí† 2.1 Download small validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c021a610",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Downloading custom dataset:**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/tutorials/open_images.html#Loading-Open-Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2ca262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to '/home/montecarlo/Desktop/scientific_computing/yolov5_course/section3/custom_dataset/open-images-v6/validation' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "{\"t\":{\"$date\":\"2025-01-11T03:22:10.459Z\"},\"s\":\"I\",  \"c\":\"CONTROL\",  \"id\":20697,   \"ctx\":\"-\",\"msg\":\"Renamed existing log file\",\"attr\":{\"oldLogPath\":\"/home/montecarlo/.fiftyone/var/lib/mongo/log/mongo.log\",\"newLogPath\":\"/home/montecarlo/.fiftyone/var/lib/mongo/log/mongo.log.2025-01-11T03-22-10\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subprocess ['/home/montecarlo/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/fiftyone/db/bin/mongod', '--dbpath', '/home/montecarlo/.fiftyone/var/lib/mongo', '--logpath', '/home/montecarlo/.fiftyone/var/lib/mongo/log/mongo.log', '--port', '0', '--nounixsocket'] exited with error 100:\n"
     ]
    },
    {
     "ename": "ServiceListenTimeout",
     "evalue": "fiftyone.core.service.DatabaseService failed to bind to port",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceListenTimeout\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m number_of_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# All 3 classes together: cat, dog, elephant\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m dataset_validation \u001b[38;5;241m=\u001b[39m \u001b[43mfoz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_zoo_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                          \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopen-images-v6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mlabel_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdetections\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mElephant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber_of_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m51\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcat-dog-elephant-150\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/fiftyone/zoo/datasets/__init__.py:399\u001b[0m, in \u001b[0;36mload_zoo_dataset\u001b[0;34m(name_or_url, split, splits, label_field, dataset_name, download_if_necessary, drop_existing_dataset, persistent, overwrite, cleanup, progress, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m importer_kwargs:\n\u001b[1;32m    397\u001b[0m         dataset_name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m importer_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m drop_existing_dataset:\n\u001b[1;32m    401\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    402\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading existing dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. To reload from disk, either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete the existing dataset or provide a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dataset_name` to use\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    405\u001b[0m             dataset_name,\n\u001b[1;32m    406\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/fiftyone/core/dataset.py:103\u001b[0m, in \u001b[0;36mdataset_exists\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdataset_exists\u001b[39m(name):\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Checks if the dataset exists.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m        True/False\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mfoo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_db_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mlist\u001b[39m(conn\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mfind({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m})\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m1\u001b[39m)))\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/fiftyone/core/odm/database.py:394\u001b[0m, in \u001b[0;36mget_db_conn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_db_conn\u001b[39m():\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a connection to the database.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m        a ``pymongo.database.Database``\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     db \u001b[38;5;241m=\u001b[39m _client[fo\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdatabase_name]\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _apply_options(db)\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/fiftyone/core/odm/database.py:233\u001b[0m, in \u001b[0;36m_connect\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m _connection_kwargs\n\u001b[0;32m--> 233\u001b[0m     \u001b[43mestablish_db_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/fiftyone/core/odm/database.py:195\u001b[0m, in \u001b[0;36mestablish_db_conn\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     _db_service \u001b[38;5;241m=\u001b[39m fos\u001b[38;5;241m.\u001b[39mDatabaseService()\n\u001b[0;32m--> 195\u001b[0m     port \u001b[38;5;241m=\u001b[39m \u001b[43m_db_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\n\u001b[1;32m    196\u001b[0m     _connection_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m port\n\u001b[1;32m    197\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFIFTYONE_PRIVATE_DATABASE_PORT\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(port)\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/fiftyone/core/service.py:277\u001b[0m, in \u001b[0;36mDatabaseService.port\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mport\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_child_port\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/fiftyone/core/service.py:171\u001b[0m, in \u001b[0;36mService._wait_for_child_port\u001b[0;34m(self, port, timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceListenTimeout(etau\u001b[38;5;241m.\u001b[39mget_class_name(\u001b[38;5;28mself\u001b[39m), port)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_port\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/retrying.py:56\u001b[0m, in \u001b[0;36mretry.<locals>.wrap.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;129m@six\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRetrying\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/retrying.py:266\u001b[0m, in \u001b[0;36mRetrying.call\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop(attempt_number, delay_since_first_attempt_ms):\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_exception \u001b[38;5;129;01mand\u001b[39;00m attempt\u001b[38;5;241m.\u001b[39mhas_exception:\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# get() on an attempt with an exception should cause it to be raised, but raise just in case\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mattempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RetryError(attempt)\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/retrying.py:301\u001b[0m, in \u001b[0;36mAttempt.get\u001b[0;34m(self, wrap_exception)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RetryError(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 301\u001b[0m         \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/six.py:724\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/retrying.py:251\u001b[0m, in \u001b[0;36mRetrying.call\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_attempts(attempt_number)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     attempt \u001b[38;5;241m=\u001b[39m Attempt(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, attempt_number, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/Desktop/scientific_computing/MachineLearningA-Z/fo-venv/lib/python3.9/site-packages/fiftyone/core/service.py:169\u001b[0m, in \u001b[0;36mService._wait_for_child_port.<locals>.find_port\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m psutil\u001b[38;5;241m.\u001b[39mError:\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ServiceListenTimeout(etau\u001b[38;5;241m.\u001b[39mget_class_name(\u001b[38;5;28mself\u001b[39m), port)\n",
      "\u001b[0;31mServiceListenTimeout\u001b[0m: fiftyone.core.service.DatabaseService failed to bind to port"
     ]
    }
   ],
   "source": [
    "# Downloading custom dataset from Open Images Dataset\n",
    "# Validation sub-dataset\n",
    "\n",
    "\n",
    "# Setting number of samples\n",
    "number_of_samples = 150\n",
    "\n",
    "\n",
    "# All 3 classes together: cat, dog, elephant\n",
    "dataset_validation = foz.load_zoo_dataset(\n",
    "                                          \"open-images-v6\",\n",
    "                                          split=\"validation\",\n",
    "                                          label_types=[\"detections\"],\n",
    "                                          classes=[\"Cat\", \"Dog\", \"Elephant\"],\n",
    "                                          max_samples=number_of_samples,\n",
    "                                          shuffle=True,\n",
    "                                          seed=51,\n",
    "                                          dataset_name=\"cat-dog-elephant-150\",\n",
    "                                         )\n",
    "\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7829263",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23d7f2",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Dataset persistence:**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/user_guide/using_datasets.html#dataset-persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing dataset information\n",
    "print(dataset_validation)\n",
    "print()\n",
    "print(\"-----\")\n",
    "print()\n",
    "\n",
    "\n",
    "# By default, datasets are non-persistent\n",
    "# Non-persistent datasets are deleted from the database each time the database is shut down\n",
    "# However, the downloaded files on the disk are untouched\n",
    "\n",
    "\n",
    "# Make the dataset persistent\n",
    "dataset_validation.persistent = True\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing dataset information\n",
    "print(dataset_validation)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54716b5",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b302252",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**FiftyOne Application:**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/user_guide/app.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fdcb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_validation = fo.load_dataset(\"cat-dog-elephant-150\")\n",
    "\n",
    "\n",
    "# Launching the App 1st time, and visualizing the dataset\n",
    "# Creating session instance\n",
    "session = fo.launch_app(dataset_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d99647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the session\n",
    "session.clear_dataset()\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The session is successfully cleared \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ab1f6",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0536c9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Deleting dataset:**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/user_guide/using_datasets.html#deleting-a-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ad3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset = fo.load_dataset(\"cat-dog-elephant-150\")\n",
    "\n",
    "# Deleting the dataset\n",
    "dataset.delete()\n",
    "\n",
    "\n",
    "# Check points\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())   # [] - list is empty\n",
    "print(dataset.name)         # \"cat-dog-elephant-150\" - the name of the deleted dataset\n",
    "print(dataset.deleted)      # if the dataset is deleted\n",
    "print()\n",
    "\n",
    "\n",
    "# (!) Pay attention\n",
    "#     We deleted the FiftyOne reference only\n",
    "#     The dataset itself (images and annotations) are saved in the hard drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004187f",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61873401",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Merging datasets:**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/tutorials/open_images.html#Loading-Open-Images  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**To ensure that we have exactly the same number of labels for each class,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;we need to download subsets separately and merge them together**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading custom dataset from Open Images Dataset\n",
    "# Validation sub-dataset\n",
    "\n",
    "\n",
    "# Setting number of samples\n",
    "number_of_samples = 50\n",
    "\n",
    "\n",
    "# All 3 classes separately: cat, dog, elephant\n",
    "# Class: cat\n",
    "dataset_validation = foz.load_zoo_dataset(\n",
    "                                          \"open-images-v6\",\n",
    "                                          split=\"validation\",\n",
    "                                          label_types=[\"detections\"],\n",
    "                                          classes=[\"Cat\"],\n",
    "                                          max_samples=number_of_samples,\n",
    "                                          shuffle=True,\n",
    "                                          seed=51,\n",
    "                                          dataset_name=\"cat-dog-elephant-150-merged\",\n",
    "                                         )\n",
    "\n",
    "\n",
    "# Class: dog\n",
    "dog_subset = foz.load_zoo_dataset(\n",
    "                                  \"open-images-v6\",\n",
    "                                  split=\"validation\",\n",
    "                                  label_types=[\"detections\"],\n",
    "                                  classes=[\"Dog\"],\n",
    "                                  max_samples=number_of_samples,\n",
    "                                  shuffle=True,\n",
    "                                  seed=51,\n",
    "                                  dataset_name=\"dog-50\",\n",
    "                                 )\n",
    "\n",
    "\n",
    "# Class: elephant\n",
    "elephant_subset = foz.load_zoo_dataset(\n",
    "                                       \"open-images-v6\",\n",
    "                                       split=\"validation\",\n",
    "                                       label_types=[\"detections\"],\n",
    "                                       classes=[\"Elephant\"],\n",
    "                                       max_samples=number_of_samples,\n",
    "                                       shuffle=True,\n",
    "                                       seed=51,\n",
    "                                       dataset_name=\"elephant-50\",\n",
    "                                      )\n",
    "\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e080c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the samples together into the one dataset\n",
    "_ = dataset_validation.merge_samples(dog_subset)\n",
    "_ = dataset_validation.merge_samples(elephant_subset)\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The datasets are successfully merged \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_validation = fo.load_dataset(\"cat-dog-elephant-150-merged\")\n",
    "\n",
    "\n",
    "# Option 1\n",
    "# Launching the App 1st time, and visualizing the dataset\n",
    "# Creating session instance\n",
    "# session = fo.launch_app(dataset_validation)\n",
    "\n",
    "\n",
    "# Option 2\n",
    "# Updating the session\n",
    "session.dataset = dataset_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the session\n",
    "session.clear_dataset()\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The session is successfully cleared \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ad0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over all the datasets that are in FiftyOne\n",
    "for dataset_name in fo.list_datasets():\n",
    "\n",
    "    # Loading again dataset into FiftyOne\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "\n",
    "    # Deleting the dataset\n",
    "    dataset.delete()\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())   # [] - list is empty\n",
    "print()\n",
    "\n",
    "\n",
    "# (!) Pay attention\n",
    "#     We deleted the FiftyOne reference only\n",
    "#     The dataset itself (images and annotations) are saved in the hard drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c0cf7",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237913c0",
   "metadata": {},
   "source": [
    "### üí† 2.2 Download full validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1560f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading custom dataset from Open Images Dataset\n",
    "# Validation dataset\n",
    "\n",
    "\n",
    "# Setting number of samples\n",
    "number_of_samples = 1000\n",
    "\n",
    "\n",
    "# All 3 classes separately: cat, dog, elephant\n",
    "# Class: cat\n",
    "dataset_validation = foz.load_zoo_dataset(\n",
    "                                          \"open-images-v6\",\n",
    "                                          split=\"validation\",\n",
    "                                          label_types=[\"detections\"],\n",
    "                                          classes=[\"Cat\"],\n",
    "                                          max_samples=number_of_samples,\n",
    "                                          seed=51,\n",
    "                                          shuffle=True,\n",
    "                                          dataset_name=\"cat-dog-elephant-validation\",\n",
    "                                         )\n",
    "\n",
    "\n",
    "# Class: dog\n",
    "dog_subset = foz.load_zoo_dataset(\n",
    "                                  \"open-images-v6\",\n",
    "                                  split=\"validation\",\n",
    "                                  label_types=[\"detections\"],\n",
    "                                  classes=[\"Dog\"],\n",
    "                                  max_samples=number_of_samples,\n",
    "                                  seed=51,\n",
    "                                  shuffle=True,\n",
    "                                  dataset_name=\"dog-1000\",\n",
    "                                 )\n",
    "\n",
    "\n",
    "# Class: elephant\n",
    "elephant_subset = foz.load_zoo_dataset(\n",
    "                                       \"open-images-v6\",\n",
    "                                       split=\"validation\",\n",
    "                                       label_types=[\"detections\"],\n",
    "                                       classes=[\"Elephant\"],\n",
    "                                       max_samples=number_of_samples,\n",
    "                                       seed=51,\n",
    "                                       shuffle=True,\n",
    "                                       dataset_name=\"elephant-1000\",\n",
    "                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the samples together into the one dataset\n",
    "_ = dataset_validation.merge_samples(dog_subset)\n",
    "_ = dataset_validation.merge_samples(elephant_subset)\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The datasets are successfully merged \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e48dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_validation = fo.load_dataset(\"cat-dog-elephant-validation\")\n",
    "\n",
    "\n",
    "# Option 1\n",
    "# Launching the App 1st time, and visualizing the dataset\n",
    "# Creating session instance\n",
    "# session = fo.launch_app(dataset_validation)\n",
    "\n",
    "\n",
    "# Option 2\n",
    "# Updating the session\n",
    "session.dataset = dataset_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the session\n",
    "session.clear_dataset()\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The session is successfully cleared \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f1b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc1c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again datasets into FiftyOne\n",
    "dataset_dog = fo.load_dataset(\"dog-1000\")\n",
    "dataset_elephant = fo.load_dataset(\"elephant-1000\")\n",
    "\n",
    "# Deleting the datasets\n",
    "dataset_dog.delete()\n",
    "dataset_elephant.delete()\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n",
    "\n",
    "\n",
    "# (!) Pay attention\n",
    "#     We deleted the FiftyOne reference only\n",
    "#     The dataset itself (images and annotations) are saved in the hard drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d15d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset persistent\n",
    "dataset_validation.persistent = True\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing dataset information\n",
    "print(dataset_validation)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd5d003",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31df58b",
   "metadata": {},
   "source": [
    "### üí† 2.3 Download full test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading custom dataset from Open Images Dataset\n",
    "# Test dataset\n",
    "\n",
    "\n",
    "# Setting number of samples\n",
    "number_of_samples = 1000\n",
    "\n",
    "\n",
    "# All 3 classes separately: cat, dog, elephant\n",
    "# Class: cat\n",
    "dataset_test = foz.load_zoo_dataset(\n",
    "                                    \"open-images-v6\",\n",
    "                                    split=\"test\",\n",
    "                                    label_types=[\"detections\"],\n",
    "                                    classes=[\"Cat\"],\n",
    "                                    max_samples=number_of_samples,\n",
    "                                    seed=51,\n",
    "                                    shuffle=True,\n",
    "                                    dataset_name=\"cat-dog-elephant-test\",\n",
    "                                   )\n",
    "\n",
    "\n",
    "# Class: dog\n",
    "dog_subset = foz.load_zoo_dataset(\n",
    "                                  \"open-images-v6\",\n",
    "                                  split=\"test\",\n",
    "                                  label_types=[\"detections\"],\n",
    "                                  classes=[\"Dog\"],\n",
    "                                  max_samples=number_of_samples,\n",
    "                                  seed=51,\n",
    "                                  shuffle=True,\n",
    "                                  dataset_name=\"dog-1000\",\n",
    "                                 )\n",
    "\n",
    "\n",
    "# Class: elephant\n",
    "elephant_subset = foz.load_zoo_dataset(\n",
    "                                       \"open-images-v6\",\n",
    "                                       split=\"test\",\n",
    "                                       label_types=[\"detections\"],\n",
    "                                       classes=[\"Elephant\"],\n",
    "                                       max_samples=number_of_samples,\n",
    "                                       seed=51,\n",
    "                                       shuffle=True,\n",
    "                                       dataset_name=\"elephant-1000\",\n",
    "                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d523d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the samples together into the one dataset\n",
    "_ = dataset_test.merge_samples(dog_subset)\n",
    "_ = dataset_test.merge_samples(elephant_subset)\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The datasets are successfully merged \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_test = fo.load_dataset(\"cat-dog-elephant-test\")\n",
    "\n",
    "\n",
    "# Option 1\n",
    "# Launching the App 1st time, and visualizing the dataset\n",
    "# Creating session instance\n",
    "# session = fo.launch_app(dataset_test)\n",
    "\n",
    "\n",
    "# Option 2\n",
    "# Updating the session\n",
    "session.dataset = dataset_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1146ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the session\n",
    "session.clear_dataset()\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The session is successfully cleared \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_dog = fo.load_dataset(\"dog-1000\")\n",
    "dataset_elephant = fo.load_dataset(\"elephant-1000\")\n",
    "\n",
    "# Deleting the datasets\n",
    "dataset_dog.delete()\n",
    "dataset_elephant.delete()\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset persistent\n",
    "dataset_test.persistent = True\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing dataset information\n",
    "print(dataset_test)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec60195",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61082f1c",
   "metadata": {},
   "source": [
    "### üí† 2.4 Download full train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83524fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_train = fo.load_dataset(\"cat-dog-elephant-train\")\n",
    "dataset_dog = fo.load_dataset(\"dog-2000\")\n",
    "dataset_elephant = fo.load_dataset(\"elephant-2000\")\n",
    "\n",
    "# Deleting the datasets\n",
    "dataset_train.delete()\n",
    "dataset_dog.delete()\n",
    "dataset_elephant.delete()\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d08436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading custom dataset from Open Images Dataset\n",
    "# Train dataset\n",
    "\n",
    "\n",
    "# (!) In case of memory issue or Kernel stopped there are 2 options\n",
    "#\n",
    "#\n",
    "#  Option 1 (to try to keep Kernel working):\n",
    "#  1. Start from 500 samples\n",
    "#  2. Run cell above to clear appropriate datasets' names\n",
    "#  3. Start this cell again but now with 1000 samples\n",
    "#  4. Run cell above to clear appropriate datasets' names\n",
    "#  5. Start this cell again but now with 1500 samples\n",
    "#  6. Run cell above to clear appropriate datasets' names\n",
    "#  7. Start this cell again but now with 2000 samples\n",
    "#\n",
    "#\n",
    "#  Option 2 (to restart Kernel each time it stops):\n",
    "#  1. Start from maximum needed value, e.g. 2000\n",
    "#  2. When Kernel stopped:\n",
    "#     2.1 Restart Kernel\n",
    "#     2.2 Repeat Step 1 (load libraries, change active directory, and set up path)\n",
    "#  3. Run cell above to clear appropriate datasets' names\n",
    "#  4. When Kernel stopped, repeat steps 2-3 until all samples are loaded\n",
    "\n",
    "\n",
    "# Setting number of samples\n",
    "number_of_samples = 2000    # or step by step: 500, 1000, 1500, and 2000\n",
    "\n",
    "\n",
    "# All 3 classes separately: cat, dog, elephant\n",
    "# Class: cat\n",
    "dataset_train = foz.load_zoo_dataset(\n",
    "                                     \"open-images-v6\",\n",
    "                                     split=\"train\",\n",
    "                                     label_types=[\"detections\"],\n",
    "                                     classes=[\"Cat\"],\n",
    "                                     max_samples=number_of_samples,\n",
    "                                     seed=51,\n",
    "                                     shuffle=True,\n",
    "                                     dataset_name=\"cat-dog-elephant-train\",\n",
    "                                    )\n",
    "\n",
    "\n",
    "# Class: dog\n",
    "dog_subset = foz.load_zoo_dataset(\n",
    "                                  \"open-images-v6\",\n",
    "                                  split=\"train\",\n",
    "                                  label_types=[\"detections\"],\n",
    "                                  classes=[\"Dog\"],\n",
    "                                  max_samples=number_of_samples,\n",
    "                                  seed=51,\n",
    "                                  shuffle=True,\n",
    "                                  dataset_name=\"dog-2000\",\n",
    "                                 )\n",
    "\n",
    "\n",
    "# Class: elephant\n",
    "elephant_subset = foz.load_zoo_dataset(\n",
    "                                       \"open-images-v6\",\n",
    "                                       split=\"train\",\n",
    "                                       label_types=[\"detections\"],\n",
    "                                       classes=[\"Elephant\"],\n",
    "                                       max_samples=number_of_samples,\n",
    "                                       seed=51,\n",
    "                                       shuffle=True,\n",
    "                                       dataset_name=\"elephant-2000\",\n",
    "                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the samples together into the one dataset\n",
    "_ = dataset_train.merge_samples(dog_subset)\n",
    "_ = dataset_train.merge_samples(elephant_subset)\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The datasets are successfully merged \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56933b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_train = fo.load_dataset(\"cat-dog-elephant-train\")\n",
    "\n",
    "\n",
    "# Option 1\n",
    "# Launching the App 1st time, and visualizing the dataset\n",
    "# Creating session instance\n",
    "# session = fo.launch_app(dataset_train)\n",
    "\n",
    "\n",
    "# Option 2\n",
    "# Updating the session\n",
    "session.dataset = dataset_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0546c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the session\n",
    "session.clear_dataset()\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The session is successfully cleared \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315be13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_dog = fo.load_dataset(\"dog-2000\")\n",
    "dataset_elephant = fo.load_dataset(\"elephant-2000\")\n",
    "\n",
    "# Deleting the datasets\n",
    "dataset_dog.delete()\n",
    "dataset_elephant.delete()\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset persistent\n",
    "dataset_train.persistent = True\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing dataset information\n",
    "print(dataset_train)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0bc857",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e8d7d",
   "metadata": {},
   "source": [
    "<a name=\"step3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539f6a9",
   "metadata": {},
   "source": [
    " ‚áß [Back to Algorithm](#algorithm) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ‚áß [Back to Step 2 content](#step2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97455307",
   "metadata": {},
   "source": [
    "# üì• Step 3: Load dataset from hard drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563f592d",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìú **Content:**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí† 3.**1** **Option 1** directly from FiftyOne  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí† 3.**2** **Option 2** from hard drive (but firstly export, and then load)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d95c411",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb074198",
   "metadata": {},
   "source": [
    "### üí† 3.**1** **Option 1** directly from FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6957febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets into FiftyOne\n",
    "dataset_train = fo.load_dataset(\"cat-dog-elephant-train\")\n",
    "dataset_validation = fo.load_dataset(\"cat-dog-elephant-validation\")\n",
    "dataset_test = fo.load_dataset(\"cat-dog-elephant-test\")\n",
    "\n",
    "\n",
    "print(\"Datasets are successfully loaded \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80228b04",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c8933",
   "metadata": {},
   "source": [
    "### üí† 3.2 Option 2 from hard drive (but firstly export, and then load)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html#basic-recipe  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#loading-datasets-from-disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42110a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing current configuration\n",
    "print(fo.config.dataset_zoo_dir)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e804a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing directory to export annotation file\n",
    "directory_to_export_dataset = os.path.join(fo.config.dataset_zoo_dir, \"open-images-v6\")\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('The directory to be activated is:')\n",
    "print(directory_to_export_dataset)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4e123",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Exporting validation dataset**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Supported formats:*  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html#supported-formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6924fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_validation = fo.load_dataset(\"cat-dog-elephant-validation\")\n",
    "\n",
    "\n",
    "# The directory to which to write the exported labels\n",
    "labels_path = os.path.join(directory_to_export_dataset, \"validation\", \"export.json\")\n",
    "\n",
    "\n",
    "# The name of the sample field containing the label that you wish to export\n",
    "# Used when exporting labeled datasets (e.g., classification or detection)\n",
    "label_field = \"detections\"\n",
    "\n",
    "\n",
    "# The type of dataset to export\n",
    "# Any subclass of `fiftyone.types.Dataset` is supported\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "\n",
    "\n",
    "# Export only labels of the detections in COCO format\n",
    "dataset_validation.export(\n",
    "                          labels_path=labels_path,\n",
    "                          dataset_type=dataset_type,\n",
    "                          label_field=label_field,\n",
    "                         )\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fba72d",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Exporting test dataset**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Supported formats:*  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html#supported-formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47790eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_test = fo.load_dataset(\"cat-dog-elephant-test\")\n",
    "\n",
    "\n",
    "# The directory to which to write the exported labels\n",
    "labels_path = os.path.join(directory_to_export_dataset, \"test\", \"export.json\")\n",
    "\n",
    "\n",
    "# The name of the sample field containing the label that you wish to export\n",
    "# Used when exporting labeled datasets (e.g., classification or detection)\n",
    "label_field = \"detections\"\n",
    "\n",
    "\n",
    "# The type of dataset to export\n",
    "# Any subclass of `fiftyone.types.Dataset` is supported\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "\n",
    "\n",
    "# Export only labels of the detections in COCO format\n",
    "dataset_test.export(\n",
    "                    labels_path=labels_path,\n",
    "                    dataset_type=dataset_type,\n",
    "                    label_field=label_field,\n",
    "                   )\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e24237",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Exporting train dataset**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Supported formats:*  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html#supported-formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_train = fo.load_dataset(\"cat-dog-elephant-train\")\n",
    "\n",
    "\n",
    "# The directory to which to write the exported labels\n",
    "labels_path = os.path.join(directory_to_export_dataset, \"train\", \"export.json\")\n",
    "\n",
    "\n",
    "# The name of the sample field containing the label that you wish to export\n",
    "# Used when exporting labeled datasets (e.g., classification or detection)\n",
    "label_field = \"detections\"\n",
    "\n",
    "\n",
    "# The type of dataset to export\n",
    "# Any subclass of `fiftyone.types.Dataset` is supported\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "\n",
    "\n",
    "# Export only labels of the detections in COCO format\n",
    "dataset_train.export(\n",
    "                     labels_path=labels_path,\n",
    "                     dataset_type=dataset_type,\n",
    "                     label_field=label_field,\n",
    "                    )\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86408168",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Loading validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d249e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A name for the dataset\n",
    "name = \"cat-dog-elephant-validation-copy\"\n",
    "\n",
    "\n",
    "# The directory with dataset\n",
    "dataset_dir = os.path.join(directory_to_export_dataset, \"validation\")\n",
    "\n",
    "\n",
    "# The path to the COCO labels JSON file\n",
    "labels_path = os.path.join(directory_to_export_dataset, \"validation\", \"export.json\")\n",
    "\n",
    "\n",
    "# The type of the dataset being imported\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "\n",
    "\n",
    "dataset_validation_copy = fo.Dataset.from_dir(\n",
    "                                              dataset_dir=dataset_dir,\n",
    "                                              dataset_type=dataset_type,\n",
    "                                              labels_path=labels_path,\n",
    "                                              name=name,\n",
    "                                             )\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing dataset information\n",
    "print(dataset_validation_copy)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ffeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_validation_copy = fo.load_dataset(\"cat-dog-elephant-validation-copy\")\n",
    "\n",
    "\n",
    "# Option 1\n",
    "# Launching the App 1st time, and visualizing the dataset\n",
    "# Creating session instance\n",
    "# session = fo.launch_app(dataset_validation_copy)\n",
    "\n",
    "\n",
    "# Option 2\n",
    "# Updating the session\n",
    "session.dataset = dataset_validation_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the session\n",
    "session.clear_dataset()\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The session is successfully cleared \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84a4f1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Loading test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A name for the dataset\n",
    "name = \"cat-dog-elephant-test-copy\"\n",
    "\n",
    "\n",
    "# The directory with dataset\n",
    "dataset_dir = os.path.join(directory_to_export_dataset, \"test\")\n",
    "\n",
    "\n",
    "# The path to the COCO labels JSON file\n",
    "labels_path = os.path.join(directory_to_export_dataset, \"test\", \"export.json\")\n",
    "\n",
    "\n",
    "# The type of the dataset being imported\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "\n",
    "\n",
    "dataset_test_copy = fo.Dataset.from_dir(\n",
    "                                        dataset_dir=dataset_dir,\n",
    "                                        dataset_type=dataset_type,\n",
    "                                        labels_path=labels_path,\n",
    "                                        name=name,\n",
    "                                       )\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2582878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing dataset information\n",
    "print(dataset_test_copy)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980dba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_test_copy = fo.load_dataset(\"cat-dog-elephant-test-copy\")\n",
    "\n",
    "\n",
    "# Option 1\n",
    "# Launching the App 1st time, and visualizing the dataset\n",
    "# Creating session instance\n",
    "# session = fo.launch_app(dataset_test_copy)\n",
    "\n",
    "\n",
    "# Option 2\n",
    "# Updating the session\n",
    "session.dataset = dataset_test_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42422da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the session\n",
    "session.clear_dataset()\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The session is successfully cleared \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf7623",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Loading train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffe02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A name for the dataset\n",
    "name = \"cat-dog-elephant-train-copy\"\n",
    "\n",
    "\n",
    "# The directory with dataset\n",
    "dataset_dir = os.path.join(directory_to_export_dataset, \"train\")\n",
    "\n",
    "\n",
    "# The path to the COCO labels JSON file\n",
    "labels_path = os.path.join(directory_to_export_dataset, \"train\", \"export.json\")\n",
    "\n",
    "\n",
    "# The type of the dataset being imported\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "\n",
    "\n",
    "dataset_train_copy = fo.Dataset.from_dir(\n",
    "                                         dataset_dir=dataset_dir,\n",
    "                                         dataset_type=dataset_type,\n",
    "                                         labels_path=labels_path,\n",
    "                                         name=name,\n",
    "                                        )\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing dataset information\n",
    "print(dataset_train_copy)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading again dataset into FiftyOne\n",
    "dataset_train_copy = fo.load_dataset(\"cat-dog-elephant-train-copy\")\n",
    "\n",
    "\n",
    "# Option 1\n",
    "# Launching the App 1st time, and visualizing the dataset\n",
    "# Creating session instance\n",
    "# session = fo.launch_app(dataset_train_copy)\n",
    "\n",
    "\n",
    "# Option 2\n",
    "# Updating the session\n",
    "session.dataset = dataset_train_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28490ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the session\n",
    "session.clear_dataset()\n",
    "\n",
    "\n",
    "# Check point\n",
    "print(\"The session is successfully cleared \\U0001F44C\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing list of loaded datasets into FiftyOne\n",
    "print(fo.list_datasets())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867124e7",
   "metadata": {},
   "source": [
    " ‚áß [Back to Algorithm](#algorithm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
